{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grupo 10: Juan Diego Perez, Diana Bayona, Jorge Rodriguez, Santiago Gutiérrez\n",
    "\n",
    "El propósito de este proyecto es poder poner en práctica los conocimientos sobre técnicas de preprocesamiento, modelos predictivos de NLP, y la disponibilización de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de género en películas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto se usará un conjunto de datos de géneros de películas. Cada observación contiene el título de una película, su año de lanzamiento, la sinopsis o plot de la película (resumen de la trama) y los géneros a los que pertenece (una película puede pertenercer a más de un género). Por ejemplo:\n",
    "- Título: 'How to Be a Serial Killer'\n",
    "- Plot: 'A serial killer decides to teach the secrets of his satisfying career to a video store clerk.'\n",
    "- Generos: 'Comedy', 'Crime', 'Horror'\n",
    "\n",
    "La idea es que usen estos datos para predecir la probabilidad de que una película pertenezca, dada la sinopsis, a cada uno de los géneros. Agradecemos al profesor Fabio González, Ph.D. y a su alumno John Arevalo por proporcionar este conjunto de datos. Ver https://arxiv.org/abs/1702.01992"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "from werkzeug.utils import cached_property\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from flask import Flask\n",
    "#from flask_restplus import Api, Resource, fields\n",
    "from flask_restx import Api, Resource, fields\n",
    "\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargue de Información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>['Short', 'Drama']</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1941</td>\n",
       "      <td>A Woman's Face</td>\n",
       "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
       "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>1954</td>\n",
       "      <td>Executive Suite</td>\n",
       "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>1990</td>\n",
       "      <td>Narrow Margin</td>\n",
       "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "6724  1941             A Woman's Face   \n",
       "4704  1954            Executive Suite   \n",
       "2582  1990              Narrow Margin   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "6724  in sweden ,  a female blackmailer with a disfi...   \n",
       "4704  in a friday afternoon in new york ,  the presi...   \n",
       "2582  in los angeles ,  the editor of a publishing h...   \n",
       "\n",
       "                                  genres  rating  \n",
       "3107                  ['Short', 'Drama']     8.0  \n",
       "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
       "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
       "4704                           ['Drama']     7.4  \n",
       "2582     ['Action', 'Crime', 'Thriller']     6.6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento\n",
    "Los datos de entrenamiento se dividen en datos de entrenamiento y validación. Si decidieron preprocesar los datos (estandarizar, normalizar, imputar valores, etc), estos son correctamente preprocesados al ajustar sobre los datos de entrenamiento (.fit_transform()) y al transformar los datos del set de validación (.transform())."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Vectorización del Campo Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Santiago/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7895, 5000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de variables predictoras (X)\n",
    "vect = TfidfVectorizer(stop_words=english_stop_words, lowercase=True, ngram_range=(1, 6),max_features=5000)\n",
    "X_dtm = vect.fit_transform(dataTraining['plot'])\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variable de interés (y)\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la parte de preprocesamiento utilizamos la función **TfidVectorizer** ya que que es mucho más efectiva para capturar la información relevante en el texto, reducir el ruido y mejorar la calidad de las características, haciendo que las palabras realmente importantes se destaquen. **TfidVectorizer** pondera la importancia relativa de los términos en función de su frecuencia en el documento. Ademas, contrario a la función **CountVectorizer**, la función TfidVectorizer tiende a mejorar el rendimiento de los modelos de ML en tareas de clasificación, ya que como hemos señalado proporciona una representación más informativa y diferenciada de los textos. Al final, esta función convierte el texto en una matriz de números para que los modelos las pueden entender y utilizar.\n",
    "\n",
    "Dentro de la función **TfidVectorizer** podemos cambiar o seleccionar algunos parámetros que nos permiten hacer un mejor preprocesamiento. En este ejercicio, eliminamos las palabras comunes que no aportan significado al texto, conocidas como 'stop_words', se eliminan palabras como: \"the\", \"of\", \"are\", \"and\". Convertimos el texto a minúsculas y le pedimos que realizara un análisis por n-gramas, analizando en este caso secuencias de 1 a 6 palabras consecutivas. Por último, limitamos el número de palabras únicas a las 5000 más comunes. \n",
    "    \n",
    "En resumen, los datos textuales de la variable plot, que contienen una breve sinopsis de cada una de las películas y que son el principal insumo para ayudarnos a predecir la probabilidad de que una pelicula pertenezca a uno o varios géneros específicos, quedan preparados para que los modelos que utilizaremos en el siguiente paso puedan procesarlos. Este preprocesamiento nos proporciona una matriz numérica de 7895 filas y 5000 columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 División Conjunto de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la bases de datos se separa la variable a predecir de sus predictoras. Luego los datos se dividen en dos muestras, una de entrenamiento y otra de validación. La muestra de entrenamiento contiene el 67% de la información y la de validación el 33% restante. Dividir los datos de esta manera nos permite ver que tambien se desempeña el modelo con información por fuera de la que utiliza para poder entrenarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calibración del Modelo \n",
    "Se calibran los parámetros que se consideren pertinentes del modelo de clasificación seleccionado. Se justifica el método seleccionado de calibración. Se analizan los valores calibrados de cada parámetro y se explica cómo afectan el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos y sus parámetros\n",
    "models = [\n",
    "    {\n",
    "        'name': 'Naive Bayes',\n",
    "        'estimator': OneVsRestClassifier(MultinomialNB()),\n",
    "        'param_grid': {\n",
    "            'clf__estimator__alpha': [0.01, 0.1, 0.15, 0.20, 0.25, 0.5, 0.75, 1.0]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'SVM',\n",
    "        'estimator': OneVsRestClassifier(SVC(probability=True)),\n",
    "        'param_grid': {\n",
    "            'clf__estimator__C': [0.1, 1],\n",
    "            'clf__estimator__kernel': ['rbf', 'sigmoid'],\n",
    "            'clf__estimator__gamma' : ['scale', 'auto']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'estimator': OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, random_state=42)),\n",
    "        'param_grid': {\n",
    "            'clf__estimator__n_estimators': [200, 300],\n",
    "            'clf__estimator__min_samples_split': [5, 10],\n",
    "            'clf__estimator__min_samples_leaf': [2, 4],\n",
    "            'clf__estimator__bootstrap': [True, False]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'XGBoost',\n",
    "        'estimator':OneVsRestClassifier(XGBClassifier(objective='binary:logistic', eval_metric='auc', use_label_encoder=False, random_state=42)),\n",
    "        'param_grid': {\n",
    "            'clf__estimator__n_estimators': [200, 300],\n",
    "            'clf__estimator__learning_rate': [0.01, 0.05, 0.1, 0.5],\n",
    "            'clf__estimator__gamma': [0, 0.5, 1],\n",
    "            'clf__estimator__colsample_bytree': [0.5, 1.0],\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_train, y_train_genres, X_test, y_test_genres, models):\n",
    "    results = []\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"Evaluando el modelo: {model['name']}\")\n",
    "        \n",
    "        pipeline = Pipeline([('clf', model['estimator'])])\n",
    "        roc_auc_scorer = make_scorer(roc_auc_score, average='macro', multi_class='ovr', needs_proba=True)# Crear el scorer para roc_auc\n",
    "        grid_search = GridSearchCV(estimator=pipeline, param_grid=model['param_grid'], \n",
    "                                   scoring=roc_auc_scorer, cv=3, verbose=2,n_jobs=-1) # Configurar y ejecutar GridSearchCV\n",
    "        \n",
    "        grid_search.fit(X_train, y_train_genres) # Entrenar el modelo\n",
    "        best_model = grid_search.best_estimator_ # Obtener el mejor modelo\n",
    "        y_pred_proba = best_model.predict_proba(X_test) # Predecir probabilidades en el conjunto de prueba\n",
    "        roc_auc = roc_auc_score(y_test_genres, y_pred_proba, average='macro') # Evaluar el modelo en el conjunto de prueba usando roc_auc_score\n",
    "        \n",
    "        # Guardar los resultados\n",
    "        results.append({\n",
    "            'model': model['name'],\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'roc_auc': roc_auc\n",
    "        })\n",
    "        \n",
    "        # Mostrar los mejores parámetros y la puntuación\n",
    "        print(f\"Mejores parámetros para {model['name']}: {grid_search.best_params_}\")\n",
    "        print(f\"Mejor puntuación de validación cruzada para {model['name']}: {grid_search.best_score_}\")\n",
    "        print(f\"ROC AUC Score en el conjunto de prueba para {model['name']}: {roc_auc}\\n\")\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar todos los modelos\n",
    "results = evaluate_model(X_train, y_train_genres, X_test, y_test_genres, models)\n",
    "\n",
    "# Mostrar los resultados\n",
    "for result in results:\n",
    "    print(f\"Modelo: {result['model']}\")\n",
    "    print(f\"Mejores parámetros: {result['best_params']}\")\n",
    "    print(f\"Mejor puntuación de validación cruzada: {result['best_score']}\")\n",
    "    print(f\"ROC AUC Score en el conjunto de prueba: {result['roc_auc']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo: Naive Bayes\n",
    "Mejores parámetros: {'clf__estimator__alpha': 0.1}\n",
    "Mejor puntuación de validación cruzada: 0.8503826776957646\n",
    "ROC AUC Score en el conjunto de prueba: 0.8657962945897676\n",
    "\n",
    "Modelo: SVM\n",
    "Mejores parámetros: {'clf__estimator__C': 0.1, 'clf__estimator__gamma': 'scale', 'clf__estimator__kernel': 'rbf'}\n",
    "Mejor puntuación de validación cruzada: 0.8391160456109027\n",
    "ROC AUC Score en el conjunto de prueba: 0.8624744738664503\n",
    "\n",
    "Modelo: Random Forest\n",
    "Mejores parámetros: {'clf__estimator__bootstrap': True, 'clf__estimator__min_samples_leaf': 4, 'clf__estimator__min_samples_split': 10, 'clf__estimator__n_estimators': 300}\n",
    "Mejor puntuación de validación cruzada: 0.8278230550291058\n",
    "ROC AUC Score en el conjunto de prueba: 0.8330338942648683\n",
    "\n",
    "Modelo: XGBoost\n",
    "Mejores parámetros: {'clf__estimator__colsample_bytree': 0.5, 'clf__estimator__gamma': 0.5, 'clf__estimator__learning_rate': 0.05, 'clf__estimator__n_estimators': 300}\n",
    "Mejor puntuación de validación cruzada: 0.8158000755448915\n",
    "ROC AUC Score en el conjunto de prueba: 0.8288969614295976"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema consiste en encontrar la probabilidad de que una película pertenezca a uno o varios géneros. Entonces, consiste en un problema de clasificación multietiqueta, donde una pelicula puede pertenecer a múltiples generos. Entre los modelos que ayudan a resolver este tipo de problemas y que son utilizados en este ejercicio se encuentran el Clasificador Naive de Bayes, las Máquinas de Soporte Vectorial (SVM), Random Forest y XGBoost. Para cada modelo, creamos un conjunto de diferentes hiperparámetros y los calibramos utilizando la función GridSearchCV de scikit-learn. Esta función busca la mejor combinación de hiperparámetros mediante una búsqueda exhaustiva, optimizando una función objetivo, en este caso, buscando el mejor AUC (Área Bajo la Curva). Utilizamos la validación cruzada para evaluar el rendimiento de cada combinación de hiperparámetros y asegurar la robustez de los resultados.\n",
    "\n",
    "Se comparan los resultados de todos los modelos y el resultado final es que el modelo con mejor desempeño, de acuerda a la metrica AUC, es el **Clasificador Naive de Bayes**. Los hiperparametros del modelo que se calibraron son: **alpha.** \n",
    "\n",
    "En un modelo de clasificación Naive Bayes, alpha es un parámetro de suavizado. En este caso, el suavizado se utiliza para manejar el problema de las probabilidades cero dentro del modelo. Esto ocurre cuando una palabra en el conjunto de datos de prueba no aparece en el conjunto de datos de entrenamiento, lo que resultaría en una probabilidad cero y podría generar sesgos al modelo. Entonces, alpha agrega un valor constante a todas las frecuencias de palabras para asegurar que ninguna probabilidad sea cero.\n",
    "\n",
    "Un valor de alpha igual a 0.1 es relativamente pequeño, lo que significa que se está aplicando un suavizado ligero. Esto ayuda a corregir las probabilidades sin alterar significativamente las frecuencias originales de las palabras. Por lo tanto, este valor implica que el modelo ha logrado encontrar un equilibrio entre adaptarse a los datos de entrenamiento sin ser demasiado vulnerable a las nuevas palabras en los datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento del Modelo\n",
    "Se entrena el modelo de clasificación escogido con los datos del set de entrenamiento preprocesados y los parámetros óptimos. Se presenta el desempeño del modelo en los datos de validación con al menos una métrica de desempeño. Se justifica la selección del modelo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10396975, 0.09640832, 0.11153119, 0.09073724, 0.12287335,\n",
       "       0.09073724, 0.10586011, 0.12476371, 0.08695652, 0.11742424])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = OneVsRestClassifier(MultinomialNB(alpha=0.1))\n",
    "cross_val_score(best_model, X_train, y_train_genres, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mejor modelo: 0.8657962945897676\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train_genres)\n",
    "y_pred_best = best_model.predict_proba(X_test)\n",
    "\n",
    "# Calcular métricas de desempeño con el mejor modelo\n",
    "auc_best_model = roc_auc_score(y_test_genres, y_pred_best, average='macro')\n",
    "\n",
    "print(\"AUC mejor modelo:\", auc_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo al apartado anterior, donde se utilizaron diferentes modelos y se utilizo la función GridSearchCV para encontrar los mejores hiperparametros para cada modelo, buscando maximizar el AUC (Área Bajo la Curva), se identifico que los mejores modelos de acuerdo a esa medida de desempeño fueron el modelo de el Clasificador Naive de Bayes y las maquinas de soporte vectorial (SVM). Siendo el Clasificador de bayes el modelo con la mejor medida de desempeño entre todos. Sobre los hiperparametros que se calibraron para este modelo, el mejor modelo es el que tiene un **alpha** de 0.1. \n",
    "\n",
    "Luego de calibrado y entrenado, se valida el desempeño del modelo con los datos de validación a través de la métrica AUC . El modelo de Clasificador Naive de Bayes, arroja un **AUC de 0.8658**. Esto significa, que el modelo tiene una alta capacidad para discriminar entre las diferentes clases de géneros de películas y que hay una probabilidad en promedio del **86,58%** de que el modelo pueda distinguir correctamente la pertenencia de una pelicula a uno o varios generos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disponibilización del Modelo\n",
    "Se disponibiliza el modelo en una API alojada en un servicio en la nube, en una instancia Ubuntu en un microservicio t2 de AWS.\n",
    "\n",
    "El link para ingresar a la API es el siguiente: [http://18.116.37.110:5000/](http://18.116.37.110:5000/).\n",
    "\n",
    "La documentación de la API se encuentra alojada en el sigueinte [link](https://github.com/JuanD13Perez/MIAD_gr10_pr2).\n",
    "\n",
    "Asimismo se cuenta con un [video explicativo del funcionamiento de la API](https://www.youtube.com/watch?v=K440L3_Ke_U).\n",
    "\n",
    "La API toma el mejor modelo que se encuentra en este Notebook para realizar sus predicciones. Recibe cmomo parámetro un texto que corresponde a la descripción (plot) de la película y devuelve los 3 géneros de película más probables. Su utilizo flask para la estructura de la aplicación.\n",
    "\n",
    "A continuación añadimos algunas líneas de código que se utilizaron para la disponibiliazación de la API. Los archivos binarios .pkl se encuentran en la carpeta de model_deployment del repositorio en donde se encuentra la documentación de la API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_deployment/genremovies.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear el directorio si no existe\n",
    "if not os.path.exists('model_deployment'):\n",
    "    os.makedirs('model_deployment')\n",
    "\n",
    "# Exportar modelo a archivo binario .pkl\n",
    "joblib.dump(best_model, 'model_deployment/genremovies.pkl', compress=3)\n",
    "joblib.dump(vect, 'model_deployment/vectorizer_tfid.pkl', compress = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar modelo y predicción\n",
    "from model_deployment.model_predictor import predict_genres\n",
    "\n",
    "# Predicción de probabilidad\n",
    "predict_genres('A couple begins to experience terrifying supernatural occurrences involving a vintage doll shortly after their home is invaded by satanic cultists. A couple begins to experience terrifying supernatural occurrences involving a vintage doll shortly after their home is invaded by satanic cultists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición aplicación Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Definición API Flask\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='API Prediccion generos de peliculas',\n",
    "    description='API que al ingresar la descripcion de una pelicula (en ingles) predice el genero de pelicula mas probable.')\n",
    "\n",
    "ns = api.namespace('Predict', \n",
    "     description='Clasificador de Generos')\n",
    "\n",
    "# Definición argumentos o parámetros de la API\n",
    "parser = api.parser()\n",
    "parser.add_argument(\n",
    "    'Descripcion', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='Descripcion de pelicula, solo texto (en ingles). Entre comillas simples.', \n",
    "    location='args')\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'result': fields.String,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase para disponibilización\n",
    "@ns.route('/')\n",
    "class GenreMovieApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    @api.marshal_with(resource_fields)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        return {\n",
    "         \"result\": predict(args['Descripcion'])\n",
    "        }, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de la aplicación que disponibiliza el modelo de manera local en el puerto 5002\n",
    "app.run(debug=True, use_reloader=False, host='0.0.0.0', port=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformación variables predictoras X del conjunto de test\n",
    "X_test_dtm = vect.transform(dataTesting['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres = best_model.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038943</td>\n",
       "      <td>0.075070</td>\n",
       "      <td>0.010077</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.455676</td>\n",
       "      <td>0.097383</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>0.576995</td>\n",
       "      <td>0.042465</td>\n",
       "      <td>0.155724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031282</td>\n",
       "      <td>0.043647</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.635412</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.165048</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.006359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085844</td>\n",
       "      <td>0.015058</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.174447</td>\n",
       "      <td>0.206193</td>\n",
       "      <td>0.247632</td>\n",
       "      <td>0.028262</td>\n",
       "      <td>0.839049</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.017758</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.084284</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.015617</td>\n",
       "      <td>0.150881</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.009607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036840</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.012149</td>\n",
       "      <td>0.236844</td>\n",
       "      <td>0.484512</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>0.283018</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>0.015995</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.395926</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.002461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059261</td>\n",
       "      <td>0.022946</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.185501</td>\n",
       "      <td>0.055952</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.708321</td>\n",
       "      <td>0.009212</td>\n",
       "      <td>0.010847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022040</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.147755</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.212581</td>\n",
       "      <td>0.040467</td>\n",
       "      <td>0.002766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.112541</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>0.470048</td>\n",
       "      <td>0.011943</td>\n",
       "      <td>0.058729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.155601</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.159348</td>\n",
       "      <td>0.315366</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.295962</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.004240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "1  0.038943     0.075070     0.010077     0.010746  0.455676  0.097383   \n",
       "4  0.085844     0.015058     0.002427     0.174447  0.206193  0.247632   \n",
       "5  0.036840     0.002419     0.000883     0.012149  0.236844  0.484512   \n",
       "6  0.059261     0.022946     0.001145     0.008924  0.185501  0.055952   \n",
       "7  0.015121     0.010662     0.003033     0.003935  0.112541  0.067476   \n",
       "\n",
       "   p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "1       0.004712  0.576995  0.042465   0.155724  ...   0.031282   0.043647   \n",
       "4       0.028262  0.839049  0.007956   0.006308  ...   0.005639   0.017758   \n",
       "5       0.002157  0.792351  0.001855   0.002696  ...   0.003198   0.283018   \n",
       "6       0.003916  0.708321  0.009212   0.010847  ...   0.022040   0.020647   \n",
       "7       0.005704  0.470048  0.011943   0.058729  ...   0.004131   0.155601   \n",
       "\n",
       "     p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "1  0.000100   0.635412  0.008209  0.002045  0.007609    0.165048  0.006099   \n",
       "4  0.000040   0.084284  0.004618  0.000854  0.015617    0.150881  0.015638   \n",
       "5  0.000035   0.118200  0.015995  0.000557  0.001982    0.395926  0.002205   \n",
       "6  0.000014   0.147755  0.034660  0.000228  0.002357    0.212581  0.040467   \n",
       "7  0.000115   0.159348  0.315366  0.002362  0.001028    0.295962  0.002330   \n",
       "\n",
       "   p_Western  \n",
       "1   0.006359  \n",
       "4   0.009607  \n",
       "5   0.002461  \n",
       "6   0.002766  \n",
       "7   0.004240  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 4. Disponibilización del Modelo\n",
    "res = pd.DataFrame(y_pred_test_genres, index=dataTesting.index, columns=cols)\n",
    "res.to_csv('pred_genres_genres_NV.csv', index_label='ID')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el conjunto de datos de peliculas con sus respectivas sinopsis en la parte del preprocesamiento se utilizó la técnica de **TfidVectorizer** para vectorizar los textos en números, eliminar las stop words y permitir un análisis por n-gramas. Por último, se divieron los datos en la muestra de entrenamiento y validación. \n",
    "\n",
    "Para la calibración, utilizamos la función GridSearchCV cambiando los hiperpárametros de los diferentes modelos que podrían ayudar a dar respuesta al problema de este ejercicio. En ese sentido, el mejor modelo que se obtuvo fue el **Clasificador Naive de Bayes**. Calibrado y entrenado, se válido el desempeño del modelo con los datos de validación a traves del AUC (Area Bajo la Curva). Arrojando un **AUC de 0.8658**, lo que indica que el modelo tiene una alta capacidad para discriminar entre las diferentes clases de géneros de películas y que hay una probabilidad en promedio del **86,58%** de que el modelo pueda distinguir correctamente la pertenencia de una pelicula a uno o varios generos.\n",
    "\n",
    "Disponibilizamos el modelo en una API Restful. Se disponibilizó a través de un microservicio en la nube en AWS. Para ello creamos dos archivos independientes, con formato tipo \"py\". El primero llamado \"model_predictor.py\" que llama el modelo \"genremovies.pkl\", realiza el preprocesamiento de los datos y realiza las predicciones. El segundo archivo, llamado \"api.py\" es el que llama la predicción y disponibiliza el modelo. \n",
    "\n",
    "Para predecir el o los generos de una pelicula a través de su sinopsis copie en la barra de búsqueda de su navegador la siguiente dirección (http://18.116.37.110:5000/), donde al ingresar y siguiendo las instrucciones puede poner la sinopsis en ingles de las peliculas que desea y esta generara las probabilidades de pertenencia de una película a uno o varios géneros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
